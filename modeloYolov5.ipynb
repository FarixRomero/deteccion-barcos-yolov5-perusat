{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov5/v70/splash.png\"></a>\n",
        "\n",
        "\n",
        "<br>\n",
        "  <a href=\"https://bit.ly/yolov5-paperspace-notebook\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
        "<br>\n",
        "\n",
        "This <a href=\"https://github.com/ultralytics/yolov5\">YOLOv5</a> üöÄ notebook by <a href=\"https://ultralytics.com\">Ultralytics</a> presents simple train, validate and predict examples to help start your AI adventure.<br>We hope that the resources in this notebook will help you get the most out of YOLOv5. Please browse the YOLOv5 <a href=\"https://docs.ultralytics.com/yolov5\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/yolov5\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "e8225db4-e61d-4640-8b1f-8bfce3331cea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 üöÄ v7.0-211-g94e943e Python-3.11.4 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete ‚úÖ (6 CPUs, 23.5 GB RAM, 324.7/1006.9 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/ultralytics/yolov5  # clone\n",
        "# %cd yolov5\n",
        "# %pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcFxRcFdJ_O",
        "outputId": "bbeeea2b-04fc-4185-aa64-258690495b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data/custom-perusat.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=16, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 1), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), 4.70 KiB | 1.57 MiB/s, done.\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   bb9706e..e4df1ec  master     -> origin/master\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 16 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
            "YOLOv5 üöÄ v7.0-211-g94e943e Python-3.11.4 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "COMET WARNING: Comet credentials have not been set. Comet will default to offline logging. Please set your credentials to enable online logging.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Using '/home/farix/python/yolov5/.cometml-runs' path as offline directory. Pass 'offline_directory' parameter into constructor or set the 'COMET_OFFLINE_DIRECTORY' environment variable to manually choose where to store offline experiment archives.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m You are trying to log string value as a metric. This is not recommended.\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/farix/python/yolov5/dataImagenPerusat/labels/train... 269 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 270/270 [00:00<00:00, 465.81it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/farix/python/yolov5/dataImagenPerusat/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 270/270 [00:00<00:00, 606.95it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/farix/python/yolov5/dataImagenPerusat/labels/val... 63 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64/64 [00:00<00:00, 699.43it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/farix/python/yolov5/dataImagenPerusat/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64/64 [00:00<00:00, 429.10it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.58 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to runs/train/exp10/labels.jpg... \n",
            "Image sizes 512 train, 512 val\n",
            "Using 6 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp10\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/59      9.31G      0.111    0.02694          0         34        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:16<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.98s/it]\n",
            "                   all         64        178      0.264      0.129     0.0937     0.0205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/59      10.1G    0.09052    0.03574          0         53        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.47s/it]\n",
            "                   all         64        178     0.0863      0.215     0.0665     0.0189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/59      10.1G    0.07956    0.03099          0         42        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.49s/it]\n",
            "                   all         64        178      0.146      0.354       0.11     0.0308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/59      10.1G    0.07323    0.02696          0         69        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.90s/it]\n",
            "                   all         64        178      0.232      0.303      0.196     0.0526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/59      10.1G    0.07188    0.02704          0         62        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.41s/it]\n",
            "                   all         64        178      0.278      0.514      0.266      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/59      10.1G    0.06867    0.02598          0         55        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.48s/it]\n",
            "                   all         64        178      0.269      0.444      0.251     0.0829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/59      10.1G    0.06563    0.02368          0         33        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.46s/it]\n",
            "                   all         64        178      0.503      0.326       0.33      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/59      10.1G    0.06565    0.02302          0         42        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.01s/it]\n",
            "                   all         64        178       0.38      0.556      0.403      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/59      10.1G    0.05936    0.02424          0        101        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.06s/it]\n",
            "                   all         64        178      0.314      0.466      0.317     0.0877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/59      10.1G    0.05676    0.02157          0         63        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.34s/it]\n",
            "                   all         64        178      0.382      0.629      0.417      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/59      10.1G    0.05289    0.02218          0         53        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.40s/it]\n",
            "                   all         64        178       0.42      0.663      0.513      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/59      10.1G    0.05302    0.02225          0         38        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s]\n",
            "                   all         64        178      0.447      0.674      0.507      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/59      10.1G    0.05224    0.02053          0         45        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.16s/it]\n",
            "                   all         64        178      0.581      0.669      0.616      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/59      10.1G    0.04899    0.02069          0         46        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.42s/it]\n",
            "                   all         64        178       0.66       0.64      0.664      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/59      10.1G    0.04871     0.0214          0         37        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.40s/it]\n",
            "                   all         64        178        0.6      0.663      0.603      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/59      10.1G    0.04928    0.02128          0         73        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.18s/it]\n",
            "                   all         64        178      0.639      0.635      0.648      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/59      10.1G    0.04678     0.0221          0         49        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.16s/it]\n",
            "                   all         64        178      0.603      0.646      0.663      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/59      10.1G    0.04632    0.02097          0         56        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.45s/it]\n",
            "                   all         64        178      0.611      0.612      0.579      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/59      10.1G    0.04582    0.01998          0         71        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:11<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.43s/it]\n",
            "                   all         64        178      0.674      0.669       0.68      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/59      10.1G     0.0463    0.01972          0         45        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.07s/it]\n",
            "                   all         64        178       0.59      0.758      0.615      0.245\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/59      10.1G    0.04572    0.02058          0         43        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.16s/it]\n",
            "                   all         64        178      0.638      0.725      0.659      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/59      10.1G     0.0423    0.01886          0         40        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.09s/it]\n",
            "                   all         64        178      0.618      0.708      0.697      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/59      10.1G    0.04326    0.01969          0         34        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.42s/it]\n",
            "                   all         64        178      0.644      0.646      0.684      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/59      10.1G     0.0431    0.02048          0         41        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.01s/it]\n",
            "                   all         64        178      0.707      0.601      0.684      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/59      10.1G    0.04159    0.01846          0         78        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.02s/it]\n",
            "                   all         64        178      0.638      0.719      0.692      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/59      10.1G    0.04216    0.01858          0         44        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.36s/it]\n",
            "                   all         64        178      0.701      0.719      0.706      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/59      10.1G    0.04228    0.01875          0         55        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.45s/it]\n",
            "                   all         64        178      0.648      0.669      0.664      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/59      10.1G    0.04044    0.01859          0         53        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.06s/it]\n",
            "                   all         64        178      0.685      0.648      0.688      0.324\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/59      10.1G    0.04059    0.01842          0         43        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.08s/it]\n",
            "                   all         64        178      0.673       0.68      0.703      0.337\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/59      10.1G    0.04171    0.01902          0         61        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.01s/it]\n",
            "                   all         64        178      0.695      0.628      0.682      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/59      10.1G    0.04016    0.01825          0         74        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.36s/it]\n",
            "                   all         64        178      0.718      0.671      0.708      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/59      10.1G    0.03939    0.01737          0         55        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.07s/it]\n",
            "                   all         64        178       0.69      0.742      0.712      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/59      10.1G     0.0388    0.01762          0         72        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.08s/it]\n",
            "                   all         64        178      0.695      0.678       0.69      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/59      10.1G     0.0389    0.01636          0         44        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.42s/it]\n",
            "                   all         64        178      0.639      0.696      0.695      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/59      10.1G    0.03869    0.01934          0         41        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s]\n",
            "                   all         64        178      0.605      0.635      0.642      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/59      10.1G    0.03671    0.01826          0         72        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.02it/s]\n",
            "                   all         64        178      0.636      0.624      0.671      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/59      10.1G    0.03767    0.01756          0         47        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.04s/it]\n",
            "                   all         64        178      0.632      0.691      0.683      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/59      10.1G    0.03725    0.01753          0         44        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.00s/it]\n",
            "                   all         64        178      0.646      0.652      0.665      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/59      10.1G    0.03742    0.01725          0         38        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.32s/it]\n",
            "                   all         64        178      0.688      0.644      0.684      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/59      10.1G    0.03599    0.01575          0         57        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s]\n",
            "                   all         64        178      0.632       0.59      0.646      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/59      10.1G    0.03515    0.01607          0         46        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s]\n",
            "                   all         64        178      0.626      0.624      0.666      0.317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/59      10.1G    0.03392    0.01623          0         61        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.37s/it]\n",
            "                   all         64        178      0.663      0.669      0.698      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/59      10.1G    0.03568    0.01771          0         52        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.35s/it]\n",
            "                   all         64        178      0.613      0.652      0.646      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/59      10.1G    0.03553    0.01513          0         27        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.00s/it]\n",
            "                   all         64        178      0.709      0.657      0.707      0.327\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/59      10.1G    0.03331    0.01483          0         55        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.05s/it]\n",
            "                   all         64        178      0.722      0.663      0.714      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/59      10.1G     0.0336      0.017          0         40        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.08s/it]\n",
            "                   all         64        178      0.664       0.68        0.7      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/59      10.1G    0.03339    0.01537          0         50        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.05s/it]\n",
            "                   all         64        178      0.729      0.646       0.71       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/59      10.1G    0.03248    0.01487          0         35        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.01it/s]\n",
            "                   all         64        178      0.735      0.663      0.724      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/59      10.1G    0.03251    0.01689          0         45        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.02it/s]\n",
            "                   all         64        178      0.689      0.622      0.675      0.323\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/59      10.1G    0.03144    0.01493          0         62        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.44s/it]\n",
            "                   all         64        178      0.734      0.668      0.704      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/59      10.1G    0.03271    0.01687          0         42        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.42s/it]\n",
            "                   all         64        178      0.712      0.685      0.714      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/59      10.1G    0.03008     0.0153          0         91        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.01s/it]\n",
            "                   all         64        178      0.702      0.702      0.717      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/59      10.1G    0.03058    0.01568          0         53        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.02it/s]\n",
            "                   all         64        178      0.688      0.702      0.705      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/59      10.1G    0.03034    0.01492          0         62        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s]\n",
            "                   all         64        178      0.661      0.685      0.692      0.341\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/59      10.1G    0.02929    0.01388          0         45        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.34s/it]\n",
            "                   all         64        178      0.667      0.652      0.699      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/59      10.1G    0.02998    0.01577          0         97        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.03it/s]\n",
            "                   all         64        178      0.738      0.635       0.72      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/59      10.1G    0.02887    0.01405          0         34        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.05s/it]\n",
            "                   all         64        178      0.746      0.644      0.734      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/59      10.1G    0.02932    0.01411          0         51        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.34s/it]\n",
            "                   all         64        178      0.712      0.665      0.727      0.343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/59      10.1G    0.02822    0.01372          0         42        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.30s/it]\n",
            "                   all         64        178      0.712      0.667      0.726      0.342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/59      10.1G    0.02827    0.01372          0         23        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:10<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.02s/it]\n",
            "                   all         64        178        0.7      0.652      0.724      0.344\n",
            "\n",
            "60 epochs completed in 0.247 hours.\n",
            "Optimizer stripped from runs/train/exp10/weights/last.pt, 173.0MB\n",
            "Optimizer stripped from runs/train/exp10/weights/best.pt, 173.0MB\n",
            "\n",
            "Validating runs/train/exp10/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.10s/it]\n",
            "                   all         64        178      0.737      0.635       0.72      0.352\n",
            "Results saved to \u001b[1mruns/train/exp10\u001b[0m\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml OfflineExperiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : [OfflineExperiment will get URL after upload]\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [102]                 : (0.49972301721572876, 2.337800979614258)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5 [120]      : (0.0664985270057302, 0.7337949433038725)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP_0.5:0.95 [120] : (0.018914307160487913, 0.35326625310831605)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision [120]    : (0.08634146622981964, 0.7462777266698836)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall [120]       : (0.12921348314606743, 0.7584269662921348)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [120]       : (0.02821696735918522, 0.11100465804338455)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/obj_loss [120]       : (0.013716567307710648, 0.03573743626475334)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [120]         : (0.04259870946407318, 0.09404146671295166)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss               : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/obj_loss [120]         : (0.01740356534719467, 0.025456544011831284)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr0 [120]                : (0.00043, 0.08560000000000001)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr1 [120]                : (0.00043, 0.009175)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     x/lr2 [120]                : (0.00043, 0.009175)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name                        : exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_batch_metrics     : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_confusion_matrix  : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_log_per_class_metrics : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_max_image_uploads     : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_mode                  : online\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     comet_model_name            : yolov5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams             : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     offline_experiment          : True\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     anchor_t            : 4.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact_alias      : latest\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size          : 16\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bbox_interval       : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     box                 : 0.05\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     bucket              : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cfg                 : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls                 : 0.006250000000000001\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_pw              : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     copy_paste          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cos_lr              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     degrees             : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device              : \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     entity              : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     evolve              : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     exist_ok            : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fl_gamma            : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fliplr              : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flipud              : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     freeze              : [0]\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_h               : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_s               : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hsv_v               : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|anchor_t        : 4.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|box             : 0.05\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls             : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|cls_pw          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|copy_paste      : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|degrees         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fl_gamma        : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|fliplr          : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|flipud          : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_h           : 0.015\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_s           : 0.7\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|hsv_v           : 0.4\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|iou_t           : 0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lr0             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|lrf             : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mixup           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|momentum        : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|mosaic          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj             : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|obj_pw          : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|perspective     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|scale           : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|shear           : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|translate       : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_bias_lr  : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_epochs   : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|warmup_momentum : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hyp|weight_decay    : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     image_weights       : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz               : 512\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     iou_t               : 0.2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     label_smoothing     : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     local_rank          : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0                 : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lrf                 : 0.01\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mixup               : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     momentum            : 0.937\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     mosaic              : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     multi_scale         : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                : exp\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noautoanchor        : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noplots             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     nosave              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     noval               : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj                 : 0.6400000000000001\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     obj_pw              : 1.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer           : SGD\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     patience            : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     perspective         : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     project             : runs/train\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     quad                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     rect                : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     resume              : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_dir            : runs/train/exp10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     save_period         : -1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     scale               : 0.5\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     shear               : 0.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     single_cls          : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     sync_bn             : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     translate           : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     upload_dataset      : False\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_conf_threshold  : 0.001\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_iou_threshold   : 0.6\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_bias_lr      : 0.1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_epochs       : 3.0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     warmup_momentum     : 0.8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     weight_decay        : 0.0005\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     workers             : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                        : 13 (1.09 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix             : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images                       : 6\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still saving offline stats to messages file before program termination (may take up to 120 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Starting saving the offline archive\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m To upload this offline experiment, run:\n",
            "    comet upload /home/farix/python/yolov5/.cometml-runs/0ca95c088db74069aff3b9dfb2250e94.zip\n"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5s on custom for 50 epochs   CODIGO PARA ENTRENAR\n",
        "!python train.py --img 512 --batch 16 --epochs 60 --data data/custom-perusat.yaml --weights yolov5x.pt --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/farix/python/yolov5/runs/train/exp10/weights/best.pt'], source=/home/farix/python/dataset/TPPaita/IMG_PER1_20210317_block_2_2_block_12800_7168.png, data=data/coco128.yaml, imgsz=[9003, 9003], conf_thres=0.7, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 üöÄ v7.0-211-g94e943e Python-3.11.4 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "WARNING ‚ö†Ô∏è --img-size [9003, 9003] must be multiple of max stride 32, updating to [9024, 9024]\n",
            "image 1/1 /home/farix/python/dataset/TPPaita/IMG_PER1_20210317_block_2_2_block_12800_7168.png: 9024x5472 24 ships, 133078.3ms\n",
            "Speed: 42.4ms pre-process, 133078.3ms inference, 19.6ms NMS per image at shape (1, 3, 9024, 9024)\n",
            "Results saved to \u001b[1mruns/detect/exp29\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !python detect.py --weights /home/farix/python/yolov5/runs/train/exp10/weights/best.pt --img 2200 --conf 0.7 --source \"/home/farix/python/yolov5/dataimages2/images/train/block_1_1.png\"\n",
        "!python detect.py --weights /home/farix/python/yolov5/runs/train/exp10/weights/best.pt --img 9003 --conf 0.7 --source \"/home/farix/python/dataset/TPPaita/IMG_PER1_20210317_block_2_2_block_12800_7168.png\"\n",
        "# display.Image(filename=\"/home/farix/python/yolov5/block_1_1.png\", width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/farix/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 üöÄ 2023-8-24 Python-3.11.4 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "Adding AutoShape... \n",
            "image 1/1: 2281x1976 9 ships\n",
            "Speed: 133.1ms pre-process, 363.6ms inference, 2.5ms NMS per image at shape (1, 3, 2208, 1920)\n",
            "Saved 1 image to \u001b[1mruns/detect/exp31\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>confidence</th>\n",
              "      <th>class</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>234.082184</td>\n",
              "      <td>697.642578</td>\n",
              "      <td>303.629364</td>\n",
              "      <td>812.521912</td>\n",
              "      <td>0.848462</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>144.547684</td>\n",
              "      <td>348.289917</td>\n",
              "      <td>182.428452</td>\n",
              "      <td>426.078186</td>\n",
              "      <td>0.840248</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>655.060974</td>\n",
              "      <td>984.461365</td>\n",
              "      <td>686.169556</td>\n",
              "      <td>1022.273071</td>\n",
              "      <td>0.822460</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>799.121033</td>\n",
              "      <td>1463.272217</td>\n",
              "      <td>820.369141</td>\n",
              "      <td>1481.489868</td>\n",
              "      <td>0.820867</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.127518</td>\n",
              "      <td>53.398842</td>\n",
              "      <td>105.245827</td>\n",
              "      <td>149.981537</td>\n",
              "      <td>0.794955</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>601.718018</td>\n",
              "      <td>1072.581421</td>\n",
              "      <td>642.306091</td>\n",
              "      <td>1098.574341</td>\n",
              "      <td>0.734567</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>636.831970</td>\n",
              "      <td>1355.060669</td>\n",
              "      <td>661.000610</td>\n",
              "      <td>1376.495483</td>\n",
              "      <td>0.717595</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>727.261841</td>\n",
              "      <td>1137.223511</td>\n",
              "      <td>750.752258</td>\n",
              "      <td>1168.930420</td>\n",
              "      <td>0.704416</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>701.601685</td>\n",
              "      <td>1301.115601</td>\n",
              "      <td>729.206421</td>\n",
              "      <td>1323.566284</td>\n",
              "      <td>0.702612</td>\n",
              "      <td>0</td>\n",
              "      <td>ship</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         xmin         ymin        xmax         ymax  confidence  class  name\n",
              "0  234.082184   697.642578  303.629364   812.521912    0.848462      0  ship\n",
              "1  144.547684   348.289917  182.428452   426.078186    0.840248      0  ship\n",
              "2  655.060974   984.461365  686.169556  1022.273071    0.822460      0  ship\n",
              "3  799.121033  1463.272217  820.369141  1481.489868    0.820867      0  ship\n",
              "4   65.127518    53.398842  105.245827   149.981537    0.794955      0  ship\n",
              "5  601.718018  1072.581421  642.306091  1098.574341    0.734567      0  ship\n",
              "6  636.831970  1355.060669  661.000610  1376.495483    0.717595      0  ship\n",
              "7  727.261841  1137.223511  750.752258  1168.930420    0.704416      0  ship\n",
              "8  701.601685  1301.115601  729.206421  1323.566284    0.702612      0  ship"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "model_path = \"/home/farix/python/yolov5/runs/train/exp10/weights/best.pt\"\n",
        "\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', model_path)\n",
        "model.conf = 0.7  # NMS confidence threshold\n",
        "\n",
        "im1 = Image.open('/home/farix/python/yolov5/block_1_1.png')  # PIL image\n",
        "\n",
        "# Inference\n",
        "results = model([im1], size=2200) # batch of images\n",
        "\n",
        "# Results\n",
        "results.print()  \n",
        "results.save()  # or .show()\n",
        "\n",
        "results.xyxy[0]  # im1 predictions (tensor)\n",
        "results.pandas().xyxy[0]  # im1 predictions (pandas)\n",
        "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
        "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
        "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
        "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
        "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 üöÄ 2023-8-24 Python-3.11.4 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [160, 160, 1, 1], expected input[1, 80, 320, 144] to have 160 channels, but got 80 channels instead",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/farix/python/yolov5/tutorial.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/farix/python/yolov5/tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Obtener predicciones\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/farix/python/yolov5/tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/farix/python/yolov5/tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(img, augment\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/farix/python/yolov5/tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Aplicar supresi√≥n de no m√°ximos para eliminar detecciones duplicadas\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/farix/python/yolov5/tutorial.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m pred \u001b[39m=\u001b[39m non_max_suppression(pred, conf_thres\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m, iou_thres\u001b[39m=\u001b[39m\u001b[39m0.45\u001b[39m, classes\u001b[39m=\u001b[39mclass_index)\n",
            "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py:209\u001b[0m, in \u001b[0;36mDetectionModel.forward\u001b[0;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[1;32m    208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_augment(x)  \u001b[39m# augmented inference, None\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_once(x, profile, visualize)\n",
            "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py:121\u001b[0m, in \u001b[0;36mBaseModel._forward_once\u001b[0;34m(self, x, profile, visualize)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 121\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[1;32m    122\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
            "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:179\u001b[0m, in \u001b[0;36mC3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv3(torch\u001b[39m.\u001b[39;49mcat((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv1(x)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv2(x)), \u001b[39m1\u001b[39;49m))\n",
            "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:71\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fuse\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 71\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x))\n",
            "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/anaconda3/envs/yolov5/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [160, 160, 1, 1], expected input[1, 80, 320, 144] to have 160 channels, but got 80 channels instead"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from models.experimental import attempt_load\n",
        "from utils.dataloaders import LoadImages\n",
        "from utils.general import check_img_size, non_max_suppression\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "# Rutas de los archivos\n",
        "model_path = \"/home/farix/python/yolov5/runs/train/exp10/weights/best.pt\"\n",
        "image_path = \"/home/farix/python/yolov5/block_1_1.png\"\n",
        "\n",
        "# Cargar el modelo YOLOv5\n",
        "device = select_device('0')  # Establecer el dispositivo de GPU (cambia '0' seg√∫n tu GPU)\n",
        "model = attempt_load(model_path)\n",
        "model.to(device)  # Mover el modelo a la GPU\n",
        "\n",
        "# Clase \"ship\" con √≠ndice 0\n",
        "class_index = 0\n",
        "\n",
        "# Establecer el tama√±o de imagen\n",
        "img_size = check_img_size(640, s=model.stride.max())\n",
        "\n",
        "# Cargar la imagen\n",
        "dataset = LoadImages(image_path, img_size=img_size)\n",
        "\n",
        "# Contador para el n√∫mero total de barcos en la imagen\n",
        "total_ships = 0\n",
        "\n",
        "# Hacer inferencia en la imagen\n",
        "for path, img, im0, _, _ in dataset:\n",
        "    img = torch.from_numpy(img).to(device)\n",
        "    img = img / 255.0  # Normalizar la imagen\n",
        "\n",
        "    # Obtener predicciones\n",
        "    with torch.no_grad():\n",
        "        pred = model(img, augment=False)[0]\n",
        "\n",
        "    # Aplicar supresi√≥n de no m√°ximos para eliminar detecciones duplicadas\n",
        "    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, classes=class_index)\n",
        "\n",
        "    # Contar el n√∫mero de detecciones de la clase \"ship\"\n",
        "    count_ships = len(pred[0]) if pred and len(pred[0]) > 0 else 0\n",
        "\n",
        "    total_ships += count_ships\n",
        "\n",
        "print(f\"Total de barcos en la imagen: {total_ships} instancias\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/farix/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 üöÄ 2023-8-24 Python-3.11.4 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero total de 'guns' detectadas con confianza >= 0.4: 7\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "# Ruta al modelo personalizado\n",
        "model_path = \"/home/farix/python/yolov5/runs/train/exp10/weights/best.pt\"  # Cambia esto a la ruta correcta\n",
        "image_path = \"/home/farix/python/yolov5/block_1_1.png\"  # Cambia esto a la ruta de tu imagen\n",
        "\n",
        "# Nivel de confianza (umbral) para las detecciones\n",
        "confidence_threshold = 0.4  # Ajusta este valor seg√∫n tus necesidades\n",
        "\n",
        "# Carga el modelo personalizado\n",
        "model = torch.hub.load('ultralytics/yolov5:master', 'custom', path=model_path)\n",
        "\n",
        "# Ruta de la imagen individual\n",
        "\n",
        "# √çndice de la clase 'guns' en tu conjunto de datos (ajusta esto seg√∫n tus datos)\n",
        "class_index_guns = 0  # Ajusta el √≠ndice de la clase 'guns' seg√∫n tus datos\n",
        "\n",
        "# Carga la imagen\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# Realiza la detecci√≥n en la imagen\n",
        "results = model(img)\n",
        "\n",
        "# Filtra las detecciones de la clase 'guns' con nivel de confianza mayor al umbral\n",
        "guns_detections = results.pred[0]  # Obtiene las detecciones de la primera imagen (asumiendo una sola imagen)\n",
        "filtered_guns_detections = guns_detections[guns_detections[:, -1] == class_index_guns]\n",
        "filtered_guns_detections = filtered_guns_detections[filtered_guns_detections[:, 4] >= confidence_threshold]\n",
        "\n",
        "# Obtiene el n√∫mero total de 'guns' detectadas con confianza mayor al umbral\n",
        "guns_count = len(filtered_guns_detections)\n",
        "\n",
        "# Imprime el n√∫mero total de 'guns' detectadas con confianza mayor al umbral\n",
        "print(f\"N√∫mero total de 'guns' detectadas con confianza >= {confidence_threshold}: {guns_count}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
